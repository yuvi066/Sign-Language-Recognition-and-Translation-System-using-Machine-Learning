{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c27035-c6e3-4137-a6aa-0617e39731fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb494be-8621-425b-829a-84c78b290bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68aea50-6780-4181-97da-4e6defab6094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0be204-6fbb-430f-8813-1af411c62980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb276a8f-bb0b-4ff6-b3a2-79d3d6dcb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd8addda-bd42-4b4a-93eb-18054a24a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b54275-dedf-479c-91d1-29f884e009a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc72c68-a5c2-4fb3-85e0-f351ba625738",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cda3cff-48de-4e46-b526-b065474181d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(results):\n",
    "    # face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    poses = np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    lh = np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(63)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(63)\n",
    "    return np.concatenate([poses, lh , rh])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9eb96f8-cbec-4f9c-ad5f-4b4bb37383eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(image , results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks,mp_holistic.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6647ca53-d4f5-45d8-b0db-b070aad8517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectVideo(image, model):\n",
    "    results = model.process(image)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "317c3ed7-618f-42ce-848b-a5b10ba6e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1adc4fe3-cfa7-488f-a050-7ccb8f47aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = df[['word_id', 'word', 'sentence_id','sentence']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63de37fd-b5a3-43a0-95a9-bc62660c8e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mappings = dict(zip(selected['word'][:73], selected['word_id'][:73]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e3a2f7e-6075-4cce-b909-9b397be2afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = {'concept': [7, 30],\n",
    " 'attach': [0, 25],\n",
    " 'meter': [2, 25],\n",
    " 'owing to': [7, 30],\n",
    " 'advertisement': [0, 26],\n",
    " 'bouquet': [7, 30],\n",
    " 'altogether': [3, 28],\n",
    " 'concerned': [3, 29],\n",
    " 'unbreakable': [2, 30],\n",
    " 'accomplish': [16, 30],\n",
    " 'interaction': [2, 28],\n",
    " 'electricity': [4, 30],\n",
    " 'maker': [2, 25],\n",
    " 'impel': [2, 29],\n",
    " 'acquisition': [2, 29],\n",
    " 'elude - 2': [2, 28],\n",
    " 'court': [0, 28],\n",
    " 'persist': [4, 29],\n",
    " 'advantage': [0, 31],\n",
    " 'buddy': [0, 28],\n",
    " 'adversarial': [6, 30],\n",
    " 'accurate': [0, 29],\n",
    " 'queue': [0, 30],\n",
    " 'accent': [2, 25],\n",
    " 'adapt': [6, 30],\n",
    " 'enthusiasm': [7, 30],\n",
    " 'tender': [2, 26],\n",
    " 'awareness': [8, 30],\n",
    " 'frustration': [3, 30],\n",
    " 'compel': [0, 31],\n",
    " 'rude': [4, 30],\n",
    " 'policy': [7, 30],\n",
    " 'secured': [2, 30],\n",
    " 'elude - 1': [2, 25],\n",
    " 'everywhere': [3, 29],\n",
    " 'advert': [5, 30],\n",
    " 'effective': [0, 22],\n",
    " 'accompany': [2, 25],\n",
    " 'adopt': [6, 30],\n",
    " 'procrastinate': [7, 30],\n",
    " 'consultant': [2, 24],\n",
    " 'exceed': [3, 28],\n",
    " 'stupid': [0, 26],\n",
    " 'examination': [2, 27],\n",
    " 'mixture': [2, 30],\n",
    " 'consensus': [0, 31],\n",
    " 'candidate': [0, 31],\n",
    " 'decorate': [3, 29],\n",
    " 'menu': [2, 25],\n",
    " 'zygote': [0, 28],\n",
    " 'decisive': [3, 30],\n",
    " 'shrivel': [4, 30],\n",
    " 'analysis': [2, 29],\n",
    " 'edgy': [2, 25],\n",
    " 'rancour': [2, 28]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee8e11-f8fd-4a30-894c-67a06c0660c7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a5b6ba7a-2f87-44d0-a749-15f2f56d780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6e7394d3-788a-4fb1-a5d4-8ff37e312880",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num , label in enumerate(filtered)}\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bb402334-bc07-4cf9-b72e-8384330169ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in filtered: \n",
    "    labels.append(label_map[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "170f88bf-0b85-43bc-bb14-134cc09ecffd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDATA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DATA/boquet/1.npy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m         res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m\"\u001b[39m , val , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(frame_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mwindow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m     window\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[1;32m     14\u001b[0m sequences\u001b[38;5;241m.\u001b[39mappend(window)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "label_map = {}\n",
    "words = []\n",
    "for val in result: \n",
    "    words.append(val)\n",
    "    window = []\n",
    "    for frame_num in range(30):\n",
    "        res = None\n",
    "        try:\n",
    "            res = np.load(os.path.join(\"DATA\" , val , \"{}.npy\".format(frame_num + 1)))\n",
    "        except:\n",
    "            res = window[-1]\n",
    "        window.append(res)\n",
    "    sequences.append(window)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd342e5e-e811-44c8-bd62-8004cc295665",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23aef728-3fdf-4557-8765-11f452c6f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc5912-f918-408f-8ec5-d0c24f890545",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "84086e92-fa0b-4913-8de4-b997be84aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "be5aed8a-ab05-4ef3-acaa-11ac0b2b6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('logs')\n",
    "tb_callback = TensorBoard(log_dir = log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e0718f00-4279-4f0a-8366-e97eca7a0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "84341dec-118c-47e1-bedb-4a4ded2c75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(units=128, input_shape=(30 , 258 ) , return_sequences=True))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "# model.add(Dropout(0.5))  # Adding dropout for regularization\n",
    "model.add(Dense(units=55, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d3eb2972-7d8a-4656-b661-7104d18287f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "02163bbd-f34a-4476-99bd-d80398cde155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "2/2 [==============================] - 10s 1s/step - loss: 4.0493 - categorical_accuracy: 0.0182\n",
      "Epoch 2/2000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.0205 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.9816 - categorical_accuracy: 0.0182\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.9372 - categorical_accuracy: 0.0545\n",
      "Epoch 5/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.8940 - categorical_accuracy: 0.0545\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.8341 - categorical_accuracy: 0.0727\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.7646 - categorical_accuracy: 0.0909\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7263 - categorical_accuracy: 0.0727\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.6391 - categorical_accuracy: 0.1091\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.4752 - categorical_accuracy: 0.1273\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.3870 - categorical_accuracy: 0.2182\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.2498 - categorical_accuracy: 0.2727\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.2425 - categorical_accuracy: 0.2727\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.1852 - categorical_accuracy: 0.1818\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 2.9171 - categorical_accuracy: 0.2727\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 2.7932 - categorical_accuracy: 0.3455\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.6539 - categorical_accuracy: 0.3455\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.4582 - categorical_accuracy: 0.4182\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 2.4381 - categorical_accuracy: 0.4182\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.3105 - categorical_accuracy: 0.5091\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.3084 - categorical_accuracy: 0.4182\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.0361 - categorical_accuracy: 0.5273\n",
      "Epoch 23/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 2.0149 - categorical_accuracy: 0.5818\n",
      "Epoch 24/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.8645 - categorical_accuracy: 0.6545\n",
      "Epoch 25/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.7414 - categorical_accuracy: 0.6727\n",
      "Epoch 26/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.6055 - categorical_accuracy: 0.6182\n",
      "Epoch 27/2000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.4613 - categorical_accuracy: 0.7455\n",
      "Epoch 28/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.3321 - categorical_accuracy: 0.7636\n",
      "Epoch 29/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.2463 - categorical_accuracy: 0.8364\n",
      "Epoch 30/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1783 - categorical_accuracy: 0.8182\n",
      "Epoch 31/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.0196 - categorical_accuracy: 0.8727\n",
      "Epoch 32/2000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.0985 - categorical_accuracy: 0.8364\n",
      "Epoch 33/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.0570 - categorical_accuracy: 0.7455\n",
      "Epoch 34/2000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.1365 - categorical_accuracy: 0.7818\n",
      "Epoch 35/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.1406 - categorical_accuracy: 0.7273\n",
      "Epoch 36/2000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.0622 - categorical_accuracy: 0.8000\n",
      "Epoch 37/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.9287 - categorical_accuracy: 0.7636\n",
      "Epoch 38/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.8399 - categorical_accuracy: 0.8909\n",
      "Epoch 39/2000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.8024 - categorical_accuracy: 0.9273\n",
      "Epoch 40/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7868 - categorical_accuracy: 0.8545\n",
      "Epoch 41/2000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6964 - categorical_accuracy: 0.9273\n",
      "Epoch 42/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5598 - categorical_accuracy: 0.9818\n",
      "Epoch 43/2000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5107 - categorical_accuracy: 0.9818\n",
      "Epoch 44/2000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4741 - categorical_accuracy: 0.9818\n",
      "Epoch 45/2000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4269 - categorical_accuracy: 0.9818\n",
      "Epoch 46/2000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4174 - categorical_accuracy: 0.9455\n",
      "Epoch 47/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3590 - categorical_accuracy: 0.9818\n",
      "Epoch 48/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3461 - categorical_accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3408 - categorical_accuracy: 0.9636\n",
      "Epoch 50/2000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2639 - categorical_accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2809 - categorical_accuracy: 0.9636\n",
      "Epoch 52/2000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2690 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " model.fit(x, y , epochs=2000,callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4636a55c-3227-451f-ac0b-be6e102429ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 30, 128)           198144    \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 30, 128)           131584    \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 55)                14135     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409911 (1.56 MB)\n",
      "Trainable params: 409911 (1.56 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e7975-7e44-41da-8450-5df3bf3417fe",
   "metadata": {},
   "source": [
    "# testing the training data : >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c689a83-d763-4063-8603-7fe2cb1a74be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "correct = 0\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    temp = model.predict(np.expand_dims(x[i], axis = 0))[0]\n",
    "    predicted = words[np.argmax(temp)]\n",
    "    ans = words[np.argmax(y[i])]\n",
    "    if ans != predicted:\n",
    "        error += 1\n",
    "    else:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9f870a94-b84e-49c6-9460-9cb5c4940a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(correct / (correct + error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b1f98-1526-4405-9325-cd26681b382c",
   "metadata": {},
   "source": [
    "# TESTING ON RECORDED VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ecd3860b-cce9-4246-a1be-c4c0e025f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = [\"advertisement\",\"rude\",\"concept\",\"buddy\",\"bouquet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "550139eb-d53e-4408-a332-76966cfaf019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advertisement 60\n",
      "rude 58\n",
      "concept 37\n",
      "buddy 50\n",
      "boquet 60\n"
     ]
    }
   ],
   "source": [
    "maxFrameCount = -1\n",
    "maxWord = \"\"\n",
    "frame_sizes = {}\n",
    "# testlist = [\"advertisement\",\"rude\",\"concept\",\"electricity\" , \"buddy\" , \"maker\"]\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5 , min_tracking_confidence = 0.9) as mp_model:\n",
    "    \n",
    "    \n",
    "    for val in testlist:\n",
    "        # if val not in filtered:\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        reader = cv2.VideoCapture(os.path.join('test' , val + '.mp4'))\n",
    "        # reader = cv2.VideoCapture(os.path.join('ISL-videos' , mappings[val] + '_left__+'.mp4'))\n",
    "        # print(val + \" \" + str(reader.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "        curFrameLen = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        # print(val + \" \" + str(curFrameLen))\n",
    "        \n",
    "        for frame_no in range(120):\n",
    "            # print(frame_no)\n",
    "            # if frame_no % 2 == 0:\n",
    "               \n",
    "            ret , frame = reader.read()\n",
    "            # print(ret == None)\n",
    "\n",
    "            # if frame_no % 2 != 0:\n",
    "            #     continue\n",
    "            # else:\n",
    "            if ret:\n",
    "                i+=1\n",
    "                # if (frame_no + 1) % 5 == 0: \n",
    "                # npy_path = os.path.join(PATH,val, str(i))\n",
    "                image, results = detectVideo(frame, mp_model)\n",
    "                draw(image, results)\n",
    "                # keypoints = extraction(results)\n",
    "                # np.save(npy_path, keypoints)\n",
    "                cv2.imshow('Feed', image)\n",
    "                # i += 1\n",
    "            else:\n",
    "                pass\n",
    "                # keypoints = np.zeros(features)\n",
    "                # npy_path = os.path.join(PATH,val, str(i))\n",
    "                # i+=1\n",
    "                # np.save(npy_path, keypoints)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        # print( val , mappings[val])\n",
    "        print(val +\" \"+ str(i))\n",
    "        # temp = input(\"next ? \")\n",
    "        # if temp == 'y':\n",
    "        frame_sizes[val] = i\n",
    "        if val == 'toil':\n",
    "            break\n",
    "    reader.release() \n",
    "    cv2.destroyAllWindows()\n",
    "            # continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e0d6b454-cb52-4a59-900c-31e7c7548fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'advertisement': 60, 'rude': 58, 'concept': 37, 'buddy': 50, 'boquet': 60}\n"
     ]
    }
   ],
   "source": [
    "print(frame_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "640f412f-ae74-43f9-a449-b48108787bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial = 60 ----> 30 (2) (advertisement)\n",
      "initial = 58 ----> 29 (2) (rude)\n",
      "initial = 37 ----> 30 (5) (concept)\n",
      "initial = 50 ----> 25 (2) (buddy)\n",
      "initial = 60 ----> 30 (2) (boquet)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "result = dry_run(frame_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fe631096-312d-45f3-b726-646751af8b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'advertisement': [2, 30], 'rude': [2, 29], 'concept': [5, 30], 'buddy': [2, 25], 'boquet': [2, 30]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "524e0647-6ff9-406f-96b6-102317b65e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advertisement\n",
      "captured = 30\n",
      "dropped = 30\n",
      "------------------------------------\n",
      "rude\n",
      "captured = 29\n",
      "dropped = 29\n",
      "------------------------------------\n",
      "concept\n",
      "captured = 30\n",
      "dropped = 7\n",
      "------------------------------------\n",
      "buddy\n",
      "captured = 25\n",
      "dropped = 25\n",
      "------------------------------------\n",
      "boquet\n",
      "captured = 30\n",
      "dropped = 30\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "maxFrameCount = -1\n",
    "maxWord = \"\"\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5 , min_tracking_confidence = 0.9) as mp_model:\n",
    "    \n",
    "    \n",
    "    for val in result:\n",
    "        \n",
    "        try: \n",
    "            os.makedirs( os.path.join(PATH,val) )\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        i = 1\n",
    "        dropped = 0\n",
    "        captured = 0\n",
    "        \n",
    "        # reader = cv2.VideoCapture(os.path.join('ISL-videos' , mappings[val] + '.mp4'))\n",
    "        reader = cv2.VideoCapture(os.path.join('test' , val + '.mp4'))\n",
    "        # print(val + \" \" + str(reader.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "        # curFrameLen = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        # print(val + \" \" + str(curFrameLen))\n",
    "        to_skip = result[val][0]\n",
    "        # print(\"to drop \" ) \n",
    "        # print(to_skip)\n",
    "        for frame_no in range(120):\n",
    "            # print(frame_no)\n",
    "            # if frame_no % 2 == 0:\n",
    "               \n",
    "            ret , frame = reader.read()\n",
    "            # print(ret == None)\n",
    "\n",
    "            # if frame_no % 2 != 0:\n",
    "            #     continue\n",
    "            # else:\n",
    "            if ret:\n",
    "                if (to_skip > 0) and ((i%to_skip) == 0):\n",
    "                    # print(\"HI\")\n",
    "                    i+=1\n",
    "                    dropped += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    i+=1\n",
    "                    captured +=1 \n",
    "                    # if (frame_no + 1) % 5 == 0: \n",
    "                    npy_path = os.path.join(\"test_frames\",val, str(captured))\n",
    "                    image, results = detectVideo(frame, mp_model)\n",
    "                    draw(image, results)\n",
    "                    keypoints = extraction(results)\n",
    "                    # print(keypoints.shape)\n",
    "                    np.save(npy_path, keypoints)\n",
    "                    cv2.imshow('Feed', image)\n",
    "                # i += 1\n",
    "            else:\n",
    "                pass\n",
    "                # keypoints = np.zeros(features)\n",
    "                # npy_path = os.path.join(PATH,val, str(i))\n",
    "                # i+=1\n",
    "                # np.save(npy_path, keypoints)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        # print( val , mappings[val])\n",
    "        print(val)\n",
    "        print(f'captured = {captured}')\n",
    "        # print(f'expected {frame_sizes[val]}')\n",
    "        # print(f'calculated {filtered[val][1]}')\n",
    "        print(f'dropped = {dropped}')\n",
    "        # print(f'work = {filtered[val]}')\n",
    "        print(\"------------------------------------\")\n",
    "        \n",
    "        # temp = input(\"next ? \")\n",
    "        # if temp == 'y':\n",
    "        # frame_sizes[val] = i\n",
    "        reader.release()\n",
    "        cv2.destroyAllWindows()\n",
    "            # continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67c6757c-f712-40c7-b586-45a998004c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "# label_map = {}\n",
    "# words = []\n",
    "for val in result: \n",
    "    words.append(val)\n",
    "    window = []\n",
    "    for frame_num in range(30):\n",
    "        res = None\n",
    "        try:\n",
    "            res = np.load(os.path.join(\"test_frames\" , val , \"{}.npy\".format(frame_num + 1)))\n",
    "        except:\n",
    "            res = window[-1]\n",
    "        window.append(res)\n",
    "    sequences.append(window)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e266b794-b39e-4d1f-b372-372c7dc86438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "56736eb9-7550-4f9c-9dab-6ef5f24fde1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1393db61-f70b-4187-b010-96a5c7bd9b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['advertisement', 'rude', 'concept', 'buddy', 'boquet']\n"
     ]
    }
   ],
   "source": [
    "print(testlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c655d79a-bbc0-448f-bcad-1dc9a76d55fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "accompany\n",
      "advertisement\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "interaction\n",
      "rude\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "compel\n",
      "concept\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "exceed\n",
      "buddy\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "accompany\n",
      "boquet\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "correct = 0\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    temp = model.predict(np.expand_dims(x_test[i], axis = 0))[0]\n",
    "    predicted = words[np.argmax(temp)]\n",
    "    print(predicted)\n",
    "    print(testlist[i])\n",
    "    # ans = words[np.argmax(y_train[i])]\n",
    "    ans = testlist[i]\n",
    "    if ans != predicted:\n",
    "        error += 1\n",
    "    else:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce88f4-343c-4c03-85bb-6868120f457c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
